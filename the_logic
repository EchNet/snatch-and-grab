Database:
  A mongo collection, indexed by URI.
  for each URI, Tracks:
    - the last updated time
    - the response headers - the digested content of the page

Worker:
  [startup]
  Read the control block
  Set the URL either from the command line, the queue, or the control block.
  If I have no URL, exit.
  Canonicalize the URL(?)

  [fetch]
  Look up the DB record for the URL.
  If there is a DB record:
    If document record was written by a different version of worker, remove it.
	Else If document has been checked within the freshness period, leave.
	Else:
	  Fetch the headers from the URL.
	  (If server is unreachable, it will come around again)
		send a message (can cause the control
		exit
	  Update last accessed time on document record.
	  If headers match document record, exit.
	  If header request fails, log and exit.
	end
  end
  Fetch the document.
  If request failed, log and exit.

  [digest]
  Produce a digest of the document contents.
  If the digest matches that of the document record, log and exit.
  Create/update the document record.
	- URL
	- status
	- headers
	- worker version
	- digest

  [followup]
  If the digest contains information to be indexed, send messages
  If the digest contains links, append them to the queue.

Logger:
  Write all messages to aggregate log.

Master Main:
  Listen to messages, maintain a model of workers.
  Schedule new workers as workers finish.
  Kill and clean up after stuck workers.
  Respond to change in error rate by adjusting sleep period and max worker count
  If a new master starts, exit.

Master Web Server:
  simple page provides:
	# of jobs in queue
	# of workers
    # of network errors in last minute, 15 seconds, 5 seconds.
	# of updates in last minute, 15 seconds, 5 seconds.
	size of index (and other search engine stats?)
  refreshes every 5 seconds
